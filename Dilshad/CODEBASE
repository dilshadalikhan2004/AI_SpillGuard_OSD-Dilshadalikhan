# ================================
# STEP 1: Install dependencies
# ================================
!pip install tensorflow keras flask flask-ngrok opencv-python-headless

# ================================
# STEP 2: Mount Google Drive (Colab only)
# ================================
from google.colab import drive
drive.mount('/content/drive')

import zipfile
import os

# Path to dataset zip file on Google Drive
zip_file_path = "/content/drive/MyDrive/dataset.zip"
# Path where dataset will be extracted
extracted_path = "/content/drive/MyDrive/dataset"

# Create folder if it doesn’t exist
os.makedirs(extracted_path, exist_ok=True)

# Extract dataset
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extracted_path)

print(f"✅ Successfully extracted {zip_file_path} to {extracted_path}")

# Global dataset path
DATASET_PATH = "/content/drive/MyDrive/dataset"


# ================================
# STEP 3: Import libraries
# ================================
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Resize all images to this shape
IMG_SIZE = (128, 128)


# ================================
# STEP 4: Dataset Loader Function
# ================================
def load_dataset(img_dir, mask_dir):
    """
    Loads images and corresponding masks.
    - Resizes them to IMG_SIZE
    - Normalizes pixel values (0-1)
    - Matches image with its mask using filename
    """
    images, masks = [], []
    valid_exts = (".png", ".jpg", ".jpeg")

    # Dictionary {basename: filename} for masks
    mask_files = {os.path.splitext(f)[0]: f for f in os.listdir(mask_dir) if f.lower().endswith(valid_exts)}

    for filename in os.listdir(img_dir):
        if filename.lower().endswith(valid_exts):
            img_name = os.path.splitext(filename)[0]  # base name without extension

            if img_name in mask_files:  # Ensure mask exists
                img_path = os.path.join(img_dir, filename)
                mask_path = os.path.join(mask_dir, mask_files[img_name])

                try:
                    # Load and resize
                    img = load_img(img_path, target_size=IMG_SIZE)
                    mask = load_img(mask_path, target_size=IMG_SIZE, color_mode="grayscale")

                    # Convert to array + normalize
                    img = img_to_array(img) / 255.0
                    mask = img_to_array(mask) / 255.0

                    images.append(img)
                    masks.append(mask)

                except Exception as e:
                    print(f"⚠️ Could not load image or mask for {filename}: {e}")
            else:
                print(f"⚠️ Skipped {filename} (mask not found)")

    return np.array(images), np.array(masks)


# ================================
# STEP 5: Load train, val, test datasets
# ================================
train_images, train_masks = load_dataset(
    os.path.join(DATASET_PATH, "train/images"),
    os.path.join(DATASET_PATH, "train/masks")
)
val_images, val_masks = load_dataset(
    os.path.join(DATASET_PATH, "val/images"),
    os.path.join(DATASET_PATH, "val/masks")
)
test_images, test_masks = load_dataset(
    os.path.join(DATASET_PATH, "test/images"),
    os.path.join(DATASET_PATH, "test/masks")
)

print("Train:", train_images.shape, train_masks.shape)
print("Val:", val_images.shape, val_masks.shape)
print("Test:", test_images.shape, test_masks.shape)


# ================================
# STEP 6: Define U-Net Model
# ================================
def unet_model(input_size=(128, 128, 3)):
    """
    Builds a U-Net architecture for image segmentation.
    Encoder: extracts features
    Bottleneck: deep representation
    Decoder: reconstructs segmented mask
    """
    inputs = Input(input_size)

    # Encoder
    c1 = Conv2D(64, 3, activation="relu", padding="same")(inputs)
    c1 = Conv2D(64, 3, activation="relu", padding="same")(c1)
    p1 = MaxPooling2D()(c1)

    c2 = Conv2D(128, 3, activation="relu", padding="same")(p1)
    c2 = Conv2D(128, 3, activation="relu", padding="same")(c2)
    p2 = MaxPooling2D()(c2)

    c3 = Conv2D(256, 3, activation="relu", padding="same")(p2)
    c3 = Conv2D(256, 3, activation="relu", padding="same")(c3)
    p3 = MaxPooling2D()(c3)

    # Bottleneck
    c4 = Conv2D(512, 3, activation="relu", padding="same")(p3)
    c4 = Conv2D(512, 3, activation="relu", padding="same")(c4)

    # Decoder
    u5 = Conv2DTranspose(256, 2, strides=2, padding="same")(c4)
    u5 = concatenate([u5, c3])
    c5 = Conv2D(256, 3, activation="relu", padding="same")(u5)
    c5 = Conv2D(256, 3, activation="relu", padding="same")(c5)

    u6 = Conv2DTranspose(128, 2, strides=2, padding="same")(c5)
    u6 = concatenate([u6, c2])
    c6 = Conv2D(128, 3, activation="relu", padding="same")(u6)
    c6 = Conv2D(128, 3, activation="relu", padding="same")(c6)

    u7 = Conv2DTranspose(64, 2, strides=2, padding="same")(c6)
    u7 = concatenate([u7, c1])
    c7 = Conv2D(64, 3, activation="relu", padding="same")(u7)
    c7 = Conv2D(64, 3, activation="relu", padding="same")(c7)

    # Output layer (1 channel, sigmoid for binary mask)
    outputs = Conv2D(1, 1, activation="sigmoid")(c7)

    return Model(inputs=[inputs], outputs=[outputs])

# Compile model
model = unet_model()
model.compile(optimizer=Adam(1e-4), loss="binary_crossentropy", metrics=["accuracy"])
model.summary()


# ================================
# STEP 7: Train the model (initial training)
# ================================
history = model.fit(
    train_images, train_masks,
    epochs=20,
    batch_size=8,
    validation_data=(val_images, val_masks)
)

# Save trained model
model.save("spillguard_model.h5")
print("✅ Model saved as spillguard_model.h5")


# ================================
# STEP 8: Test prediction on sample image
# ================================
sample_img = test_images[0]
sample_mask = test_masks[0]

pred = model.predict(np.expand_dims(sample_img, axis=0))[0]

plt.subplot(1,3,1); plt.title("Original"); plt.imshow(sample_img)
plt.subplot(1,3,2); plt.title("Ground Truth"); plt.imshow(sample_mask[:,:,0], cmap="gray")
plt.subplot(1,3,3); plt.title("Predicted"); plt.imshow(pred[:,:,0], cmap="gray")
plt.show()


# ================================
# STEP 9: Continue Training (Resume from saved model)
# ================================
from tensorflow.keras.callbacks import ModelCheckpoint

# Load previous best model
model = load_model("spillguard_model.h5", compile=False)
model.compile(optimizer=Adam(1e-4), loss="binary_crossentropy", metrics=["accuracy"])

# Save best model checkpoint
checkpoint = ModelCheckpoint("spillguard_model.h5", monitor="val_loss", save_best_only=True, verbose=1)

# Train more (epochs 20 → 120)
history_more = model.fit(
    train_images, train_masks,
    epochs=120,
    initial_epoch=20,   # resume from epoch 20
    batch_size=8,
    validation_split=0.2,
    callbacks=[checkpoint]
)


# Train further (epochs 120 → 200)
history_more = model.fit(
    train_images, train_masks,
    epochs=200,
    initial_epoch=120,  # resume from epoch 120
    batch_size=8,
    validation_split=0.2,
    callbacks=[checkpoint]
)


# ================================
# STEP 10: Flask Deployment
# ================================
import os
from flask import Flask, request
from flask_ngrok import run_with_ngrok

UPLOAD_FOLDER = "uploads"
IMG_SIZE = (128, 128)

app = Flask(__name__)
run_with_ngrok(app)  # ngrok for public URL in Colab
app.config["UPLOAD_FOLDER"] = UPLOAD_FOLDER

# Create required folders
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs("static", exist_ok=True)

# Load trained model
model = load_model("spillguard_model.h5", compile=False)

# --- Helper Functions ---
def preprocess_image(image_path):
    """Load image and preprocess for model"""
    img = load_img(image_path, target_size=IMG_SIZE)
    img_arr = img_to_array(img) / 255.0
    return np.expand_dims(img_arr, axis=0)

def predict_mask(image_path):
    """Predict segmentation mask for uploaded image"""
    img_array = preprocess_image(image_path)
    pred_mask = model.predict(img_array)[0]
    confidence = float(np.mean(pred_mask))  # crude confidence metric

    orig_img = cv2.imread(image_path)
    pred_mask_resized = cv2.resize(pred_mask, (orig_img.shape[1], orig_img.shape[0]))
    return orig_img, pred_mask_resized, confidence

def create_overlay(original, mask):
    """Overlay predicted mask as heatmap"""
    heatmap = cv2.applyColorMap((mask * 255).astype(np.uint8), cv2.COLORMAP_JET)
    overlay = cv2.addWeighted(original, 0.7, heatmap, 0.3, 0)
    return overlay

# --- Flask Routes ---
@app.route("/", methods=["GET", "POST"])
def upload_predict():
    if request.method == "POST":
        file = request.files["file"]
        filepath = os.path.join(app.config["UPLOAD_FOLDER"], file.filename)
        file.save(filepath)

        # Run prediction
        orig_img, mask, confidence = predict_mask(filepath)

        # Save mask and overlay images
        mask_path = os.path.join("static", "pred_mask.png")
        cv2.imwrite(mask_path, (mask * 255).astype(np.uint8))

        overlay = create_overlay(orig_img, mask)
        overlay_path = os.path.join("static", "overlay.png")
        cv2.imwrite(overlay_path, overlay)

        # Show results in browser
        return f"""
        <h2>Prediction Confidence: {round(confidence*100,2)}%</h2>
        <h3>Original</h3><img src='/{filepath}' width='400'>
        <h3>Mask</h3><img src='/{mask_path}' width='400'>
        <h3>Overlay</h3><img src='/{overlay_path}' width='400'>
        """
    return '''
    <h1>Upload Oil Spill Image</h1>
    <form method="post" enctype="multipart/form-data">
      <input type="file" name="file">
      <input type="submit">
    </form>
    '''

# Start Flask app
app.run()
